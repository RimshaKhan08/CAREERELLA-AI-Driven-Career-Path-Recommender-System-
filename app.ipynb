{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a9ad432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# import pickle\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # ------------------- Load and preprocess data -------------------\n",
    "# data = pd.read_csv('career_dataset_large.csv')\n",
    "\n",
    "# cols = ['Skills', 'Interests', 'Personality', 'Experience', 'Career']\n",
    "\n",
    "# # Convert values to lowercase\n",
    "# for col in cols:\n",
    "#     if col in ['Skills', 'Interests']:\n",
    "#         data[col] = data[col].apply(lambda x: ', '.join([i.strip().lower() for i in x.split(',')]))\n",
    "#     else:\n",
    "#         data[col] = data[col].str.lower()\n",
    "\n",
    "# # Convert Skills and Interests into lists\n",
    "# data['Skills'] = data['Skills'].apply(lambda x: [s.strip() for s in x.split(',')])\n",
    "# data['Interests'] = data['Interests'].apply(lambda x: [i.strip() for i in x.split(',')])\n",
    "\n",
    "# # MultiLabelBinarizer for Skills and Interests\n",
    "# mlb_skills = MultiLabelBinarizer()\n",
    "# skills_encoded = mlb_skills.fit_transform(data['Skills'])\n",
    "\n",
    "# mlb_interests = MultiLabelBinarizer()\n",
    "# interests_encoded = mlb_interests.fit_transform(data['Interests'])\n",
    "\n",
    "# skills_df = pd.DataFrame(skills_encoded, columns=mlb_skills.classes_).reset_index(drop=True)\n",
    "# interests_df = pd.DataFrame(interests_encoded, columns=mlb_interests.classes_).reset_index(drop=True)\n",
    "\n",
    "# # OneHotEncoder for Personality, Experience, Career\n",
    "# ohe = OneHotEncoder(sparse=False)\n",
    "# features_to_ohe = data[['Personality','Experience','Career']]\n",
    "# ohe_encoded_features = ohe.fit_transform(features_to_ohe)\n",
    "# ohe_df = pd.DataFrame(ohe_encoded_features, columns=ohe.get_feature_names_out(features_to_ohe.columns)).reset_index(drop=True)\n",
    "\n",
    "# # Combine all features\n",
    "# final_df = pd.concat([skills_df, interests_df, ohe_df], axis=1)\n",
    "\n",
    "# # Split features and target\n",
    "# X = final_df.drop(columns=[col for col in final_df.columns if 'Career_' in col])\n",
    "# y = final_df[[col for col in final_df.columns if 'Career_' in col]]\n",
    "\n",
    "# # Save career columns for API\n",
    "# career_columns = y.columns.tolist()\n",
    "# with open(\"career_columns.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(career_columns, f)\n",
    "\n",
    "# # ------------------- Train/Test split -------------------\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# # ------------------- Build model -------------------\n",
    "# num_classes = y.shape[1]\n",
    "\n",
    "# model = Sequential([\n",
    "#     Dense(128, input_dim=X_train.shape[1]),\n",
    "#     BatchNormalization(),\n",
    "#     tf.keras.layers.Activation('relu'),\n",
    "#     Dropout(0.4),\n",
    "\n",
    "#     Dense(64),\n",
    "#     BatchNormalization(),\n",
    "#     tf.keras.layers.Activation('relu'),\n",
    "#     Dropout(0.2),\n",
    "\n",
    "#     Dense(32),\n",
    "#     BatchNormalization(),\n",
    "#     tf.keras.layers.Activation('relu'),\n",
    "\n",
    "#     Dense(num_classes, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# early_stop = EarlyStopping(\n",
    "#     monitor='val_loss',\n",
    "#     patience=10,\n",
    "#     restore_best_weights=True\n",
    "# )\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     validation_data=(X_test, y_test),\n",
    "#     epochs=50,\n",
    "#     batch_size=32,\n",
    "#     callbacks=[early_stop],\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# loss, accuracy = model.evaluate(X_test, y_test)\n",
    "# print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "# # ------------------- Save model -------------------\n",
    "# model.save('career_recommender_model.h5')\n",
    "\n",
    "# # ------------------- Save feature map for API -------------------\n",
    "# import pickle\n",
    "\n",
    "# feature_map = {col: idx for idx, col in enumerate(X.columns)}\n",
    "\n",
    "# with open(\"feature_map.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(feature_map, f)\n",
    "\n",
    "# print(\"Feature map saved. Total features:\", len(feature_map))\n",
    "\n",
    "# print(\"Model, feature_map.pkl, and career_columns.pkl saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8c58f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9fbf555",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('career_dataset_large.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "19ffff68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Skills  \\\n",
      "0       python, ml, cloud, data analysis, java   \n",
      "1              java, cloud, sql, data analysis   \n",
      "2                             sql, java, cloud   \n",
      "3                                   ml, python   \n",
      "4  cloud, java, sql, data analysis, management   \n",
      "\n",
      "                           Interests Personality    Experience  \\\n",
      "0                   research, coding     logical  intermediate   \n",
      "1            problem solving, coding  analytical      advanced   \n",
      "2  problem solving, coding, analysis  analytical      advanced   \n",
      "3           coding, research, devops     logical      beginner   \n",
      "4            coding, problem solving  analytical  intermediate   \n",
      "\n",
      "              Career  \n",
      "0        ai engineer  \n",
      "1  backend developer  \n",
      "2  backend developer  \n",
      "3        ai engineer  \n",
      "4  backend developer  \n"
     ]
    }
   ],
   "source": [
    "cols = ['Skills', 'Interests', 'Personality', 'Experience', 'Career']\n",
    "\n",
    "# Convert values to lowercase\n",
    "for col in cols:\n",
    "    if col in ['Skills', 'Interests']:\n",
    "        # Split the comma-separated string, lowercase each item, then join back\n",
    "        data[col] = data[col].apply(lambda x: ', '.join([i.strip().lower() for i in x.split(',')]))\n",
    "    else:\n",
    "        # Just lowercase the string\n",
    "        data[col] = data[col].str.lower()\n",
    "\n",
    "# Check result\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a8c9c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Skills'] = data['Skills'].apply(lambda x: [s.strip() for s in x.split(',')])\n",
    "data['Interests'] = data['Interests'].apply(lambda x: [i.strip() for i in x.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ba0f8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_skills = MultiLabelBinarizer()\n",
    "skills_encoded = mlb_skills.fit_transform(data['Skills'])\n",
    "\n",
    "mlb_interests = MultiLabelBinarizer()\n",
    "interests_encoded = mlb_interests.fit_transform(data['Interests'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37dfc6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_df = pd.DataFrame(skills_encoded, columns=mlb_skills.classes_).reset_index(drop=True)\n",
    "interests_df = pd.DataFrame(interests_encoded, columns=mlb_interests.classes_).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7c0d022d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rimsha Khan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "features_to_ohe = data[['Personality','Experience','Career']]\n",
    "ohe_encoded_features = ohe.fit_transform(features_to_ohe)\n",
    "ohe_df = pd.DataFrame(ohe_encoded_features, columns=ohe.get_feature_names_out(features_to_ohe.columns)).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bb9e94b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([skills_df, interests_df, ohe_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "287a23fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split features and target\n",
    "X = final_df.drop(columns=[col for col in final_df.columns if 'Career_' in col])\n",
    "y = final_df[[col for col in final_df.columns if 'Career_' in col]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2418cc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape after removing duplicates: (4000, 23)\n"
     ]
    }
   ],
   "source": [
    "X = X.loc[:, ~X.columns.duplicated()]\n",
    "print(\"X shape after removing duplicates:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5527635a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (4000, 23)\n",
      "Columns: ['cloud', 'data analysis', 'design', 'html', 'java', 'management', 'ml', 'networking', 'python', 'sql', 'analysis', 'coding', 'devops', 'leadership', 'problem solving', 'research', 'Personality_analytical', 'Personality_creative', 'Personality_logical', 'Personality_practical', 'Experience_advanced', 'Experience_beginner', 'Experience_intermediate']\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"Columns:\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec8504",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33424dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d2c971b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- Train/Test split -------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a6f67711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- Build model -------------------\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, input_dim=X_train.shape[1]),\n",
    "    BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Dense(64),\n",
    "    BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(32),\n",
    "    BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f6a6f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "97b66bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "edad8310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 1s 4ms/step - loss: 1.1356 - accuracy: 0.6184 - val_loss: 0.9439 - val_accuracy: 0.9287\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.8909 - val_loss: 0.3662 - val_accuracy: 0.9500\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3259 - accuracy: 0.9091 - val_loss: 0.1875 - val_accuracy: 0.9563\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.9175 - val_loss: 0.1380 - val_accuracy: 0.9588\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.9403 - val_loss: 0.1243 - val_accuracy: 0.9600\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2214 - accuracy: 0.9259 - val_loss: 0.1326 - val_accuracy: 0.9550\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9369 - val_loss: 0.1182 - val_accuracy: 0.9550\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1964 - accuracy: 0.9337 - val_loss: 0.1198 - val_accuracy: 0.9488\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9403 - val_loss: 0.1167 - val_accuracy: 0.9563\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1642 - accuracy: 0.9431 - val_loss: 0.1121 - val_accuracy: 0.9550\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1671 - accuracy: 0.9438 - val_loss: 0.1129 - val_accuracy: 0.9588\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1678 - accuracy: 0.9466 - val_loss: 0.1127 - val_accuracy: 0.9575\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1640 - accuracy: 0.9469 - val_loss: 0.1142 - val_accuracy: 0.9575\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1614 - accuracy: 0.9484 - val_loss: 0.1170 - val_accuracy: 0.9563\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9488 - val_loss: 0.1132 - val_accuracy: 0.9513\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1370 - accuracy: 0.9503 - val_loss: 0.1108 - val_accuracy: 0.9563\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1565 - accuracy: 0.9431 - val_loss: 0.1096 - val_accuracy: 0.9538\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.9484 - val_loss: 0.1115 - val_accuracy: 0.9575\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9481 - val_loss: 0.1148 - val_accuracy: 0.9563\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9503 - val_loss: 0.1091 - val_accuracy: 0.9588\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1341 - accuracy: 0.9519 - val_loss: 0.1155 - val_accuracy: 0.9613\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9491 - val_loss: 0.1105 - val_accuracy: 0.9563\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9556 - val_loss: 0.1114 - val_accuracy: 0.9575\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1392 - accuracy: 0.9519 - val_loss: 0.1084 - val_accuracy: 0.9600\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1251 - accuracy: 0.9588 - val_loss: 0.1128 - val_accuracy: 0.9575\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1329 - accuracy: 0.9572 - val_loss: 0.1121 - val_accuracy: 0.9588\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1278 - accuracy: 0.9556 - val_loss: 0.1183 - val_accuracy: 0.9550\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.9497 - val_loss: 0.1143 - val_accuracy: 0.9588\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9569 - val_loss: 0.1121 - val_accuracy: 0.9563\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1300 - accuracy: 0.9547 - val_loss: 0.1075 - val_accuracy: 0.9575\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.9569 - val_loss: 0.1124 - val_accuracy: 0.9575\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.9584 - val_loss: 0.1209 - val_accuracy: 0.9575\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1269 - accuracy: 0.9531 - val_loss: 0.1198 - val_accuracy: 0.9563\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1151 - accuracy: 0.9566 - val_loss: 0.1136 - val_accuracy: 0.9550\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1278 - accuracy: 0.9531 - val_loss: 0.1153 - val_accuracy: 0.9563\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9538 - val_loss: 0.1192 - val_accuracy: 0.9563\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1026 - accuracy: 0.9634 - val_loss: 0.1187 - val_accuracy: 0.9513\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.9563 - val_loss: 0.1220 - val_accuracy: 0.9550\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9516 - val_loss: 0.1180 - val_accuracy: 0.9550\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1049 - accuracy: 0.9650 - val_loss: 0.1219 - val_accuracy: 0.9525\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a14b2aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1075 - accuracy: 0.9575\n",
      "Test Accuracy: 95.75%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0485bad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rimsha Khan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# ------------------- Save model -------------------\n",
    "model.save('career_recommender_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e4e49683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save career columns for API\n",
    "career_columns = y.columns.tolist()\n",
    "with open(\"career_columns.pkl\", \"wb\") as f:\n",
    "    pickle.dump(career_columns, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "25508baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature map saved. Total features: 23\n",
      "Model, feature_map.pkl, and career_columns.pkl saved successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ------------------- Save feature map for API -------------------\n",
    "import pickle\n",
    "\n",
    "feature_map = {col: idx for idx, col in enumerate(X.columns)}\n",
    "\n",
    "with open(\"feature_map.pkl\", \"wb\") as f:\n",
    "    pickle.dump(feature_map, f)\n",
    "\n",
    "print(\"Feature map saved. Total features:\", len(feature_map))\n",
    "\n",
    "print(\"Model, feature_map.pkl, and career_columns.pkl saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
